### 背景

最近几年，随着微服务的流行，服务和服务之间的依赖越来越强，调用关系越来越复杂，服务和服务之间的稳定性越来越重要。在遇到突发的请求量激增，恶意的用户访问，亦或请求频率过高给下游服务带来较大压力时，我们常常需要通过缓存、限流、熔断降级、负载均衡等多种方式保证服务的稳定性。其中限流是不可或缺的一环，这篇文章介绍限流相关知识。

### 介绍

限流：顾名思义，就是对请求或并发数进行限制；通过对一个时间窗口内的请求量进行限制来保障系统的正常运行。如果我们的服务资源有限、处理能力有限，就需要对调用我们服务的上游请求进行限制，以防止自身服务由于资源耗尽而停止服务。
在限流中有两个概念需要了解。

阈值：在一个单位时间内允许的请求量。如 QPS 限制为10，说明 1 秒内最多接受 10 次请求。
拒绝策略：超过阈值的请求的拒绝策略，常见的拒绝策略有直接拒绝、排队等待等。

### 应用场景

现代互联网很多业务场景，比如秒杀、下单、查询商品详情，最大特点就是高并发，而往往我们的系统不能承受这么大的流量，继而产生了很多的应对措施：CDN、消息队列、多级缓存、异地多活。
但是无论如何优化，终究由硬件的物理特性决定了我们系统性能的上限，如果强行接收所有请求，往往造成雪崩。
这时候限流熔断就发挥作用了，限制请求数，快速失败，保证系统满负载又不超限。

### 拓展

除了对服务可用性的追求，微服务架构一个绕不过去的问题就是服务雪崩。

在一个调用链路上，微服务架构各个服务之间组成了一个松散的整体，牵一发而动全身，服务雪崩是一个多级传导的过程。
首先是某个服务提供者不可用，由于大量超时等待，继而导致服务调用者不可用，并且在整个链路上传导，继而导致系统瘫痪。

限流降级怎么做：
如同上面我们分析的，在大规模微服务架构的场景下，避免服务出现雪崩，要减少停机时间，要尽可能的提高服务可用性。
提高服务可用性，可以从很多方向入手，比如缓存、池化、异步化、负载均衡、队列和降级熔断等手段。
缓存以及队列等手段，增加系统的容量。限流和降级则是关心在到达系统瓶颈时系统的响应，更看重稳定性。
缓存和异步等提高系统的战力，限流降级关注的是防御。限流和降级，具体实施方法可以归纳为八字箴言，分别是限流，降级，熔断和隔离。

限流和降级：

    限流顾名思义，提前对各个类型的请求设置最高的 QPS 阈值，若高于设置的阈值则对该请求直接返回，不再调用后续资源。

    限流需要结合压测等，了解系统的最高水位，也是在实际开发中应用最多的一种稳定性保障手段。

    降级则是当服务器压力剧增的情况下，根据当前业务情况及流量对一些服务和页面有策略的降级，以此释放服务器资源以保证核心任务的正常运行。

    从降级配置方式上，降级一般可以分为主动降级和自动降级。主动降级是提前配置，自动降级则是系统发生故障时，如超时或者频繁失败，自动降级。

    其中，自动降级，又可以分为以下策略：

        超时降级
        失败次数降级
        故障降级

在系统设计中，降级一般是结合系统配置中心，通过配置中心进行推送，下面是一个典型的降级通知设计。

熔断隔离：

    如果某个目标服务调用慢或者有大量超时，此时熔断该服务的调用，对于后续调用请求，不在继续调用目标服务，直接返回，快速释放资源。

    熔断一般需要设置不同的恢复策略，如果目标服务情况好转则恢复调用。

    服务隔离与前面的三个略有区别，我们的系统通常提供了不止一个服务，但是这些服务在运行时是部署在一个实例，或者一台物理机上面的。

    如果不对服务资源做隔离，一旦一个服务出现了问题，整个系统的稳定性都会受到影响！服务隔离的目的就是避免服务之间相互影响。

    一般来说，隔离要关注两方面，一个是在哪里进行隔离，另外一个是隔离哪些资源。

    何处隔离：一次服务调用，涉及到的是服务提供方和调用方，我们所指的资源，也是两方的服务器等资源，服务隔离通常可以从提供方和调用方两个方面入手。

    隔离什么：广义的服务隔离，不仅包括服务器资源，还包括数据库分库，缓存，索引等，这里我们只关注服务层面的隔离。

降级和熔断的区别:

    服务降级和熔断在概念上比较相近，通过两个场景，谈谈我自己的理解。

    熔断，一般是停止服务：典型的就是股市的熔断，如果大盘不受控制，直接休市，不提供服务，是保护大盘的一种方式。

    降级，通常是有备用方案：从北京到济南，下雨导致航班延误，我可以乘坐高铁，如果高铁票买不到，也可以乘坐汽车或者开车过去。

    两者的区别：降级一般是主动的，有预见性的，熔断通常是被动的，服务 A 降级以后，一般会有服务 B 来代替，而熔断通常是针对核心链路的处理。

    在实际开发中，熔断的下一步通常就是降级。

### 限流算法

#### 计数器算法（固定窗口算法）

在一段时间间隔内，处理请求的最大数量固定，超过部分不做处理。这个算法的缺点就是在时间临界点会有较大瞬间流量，出现 “突刺现象”

缺点：
用户通过在时间窗口的重置节点处突发请求， 可以瞬间超过我们的速率限制，用户有可能通过算法的这个漏洞，瞬间压垮我们的应用

#### 漏桶：

漏桶大小固定，处理速度固定，但请求进入速度不固定（在突发情况请求过多时，会丢弃过多的请求）。

漏桶算法可基于线程池来实现，线程池使用固定容量的阻塞队列+固定个数的处理线程来实现

原生的漏桶算法以恒定速度出水（处理请求），但是实际场景中请求的处理耗时可能不相等，为了实现恒定速率，一般都是限定同时处理请求的最大线程数

削峰： 有大量流量进入时,会发生溢出,从而限流保护服务可用

缓冲： 不至于直接请求到服务器, 缓冲压力

漏桶的不足：

    漏桶的出水速度固定，也就是请求放行速度是固定的。

    漏桶出口的速度固定，不能灵活的应对后端能力提升。比如，通过动态扩容，后端流量从1000QPS提升到1WQPS，漏桶没有办法。

#### 令牌桶：

很多场景中，需要允许某种程度的突发请求，请求的最大速度也就是所有桶大小。这时候漏桶算法就不合适了，令牌桶算法更为适合。

令牌桶限流大致的规则如下：

    （1）进水口按照某个速度，向桶中放入令牌。
    （2）令牌的容量是固定的，但是放行的速度不是固定的，只要桶中还有剩余令牌，一旦请求过来就能申请成功，然后放行。
    （3）如果令牌的发放速度，慢于请求到来速度，桶内就无牌可领，请求就会被拒绝。

令牌桶算法的一个实现方案是：起一个 Timer 线程以固定频率往桶中放令牌，桶满时令牌溢出，业务线程在获取令牌时直接从桶中获取即可。该方案容易理解，但是需要一个 Timer 线程，资源占用较重。

令牌桶算法还有一种实现方案不需要用 Timer 线程，这个经典实现就是 Guava 中的 RateLimiter。

令牌桶的好处：

    令牌桶的好处之一就是可以方便地应对 突发出口流量（后端能力的提升）。

比如，可以改变令牌的发放速度，算法能按照新的发送速率调大令牌的发放数量，使得出口突发流量能被处理。

#### 滑动时间窗口算法

滑动时间窗口算法就是根据当前时间获取对应的时间窗口，时间窗口保存有流量相关的统计值，根据该统计值判断是否触发流控。

一般来说，时间窗口可以循环复用，在复用时重新初始化即可，具体实现可参考 sentinel 的滑动窗口实现。滑动时间窗口能够支持的瞬时流量最大可为该窗口上限，而令牌桶算法能够支持的瞬时流量最大为桶大小；注意，滑动时间窗口算法中获取 token 数量一次最大不能超过窗口上限，而 RateLimiter 实现的令牌桶可以支持一次获取超过桶大小的 token。

#### 滑动日志算法

滑动日志算法是实现限流的另一种方法，这种方法比较简单。基本逻辑就是记录下所有的请求时间点，新请求到来时先判断最近指定时间范围内的请求数量是否超过指定阈值，由此来确定是否达到限流，这种方式没有了时间窗口突变的问题，限流比较准确，但是因为要记录下每次请求的时间点，所以占用的内存较多。

### 限流方案

### 一、容器限流

#### 1. Tomcat

tomcat 能够配置连接器的最大线程数属性，该属性 maxThreads是 Tomcat 的最大线程数，当请求的并发大于 maxThreads 时，请求就会排队执行(排队数设置：accept-count)，这样就完成了限流的目的。

#### 2. Nginx

Nginx 提供了两种限流手段：一是控制速率，二是控制并发连接数。

控制速率

    我们需要使用 limit_req_zone 配置来限制单位时间内的请求数，即速率限制，示例配置如下：

        `limit_req_zone $binary_remote_addr zone=mylimit:10m rate=2r/s;`

        第一个参数：`$binary_remote_addr` 表示通过 `remote_addr` 这个标识来做限制，“binary_” 的目的是缩写内存占用量，是限制同一客户端 ip 地址。

        第二个参数：`zone=mylimit:10m` 表示生成一个大小为10M，名字为 one 的内存区域，用来存储访问的频次信息。

        第三个参数：`rate=2r/s` 表示允许相同标识的客户端的访问频次，这里限制的是每秒2次，还可以有比如 30r/m 的。

并发连接数

    利用 `limit_conn_zone ` 和 `limit_conn` 两个指令即可控制并发数，示例配置如下

        limit_conn_zone $binary_remote_addr zone=perip:10m;
        limit_conn_zone $server_name zone=perserver:10m;
        server {
            ...
            limit_conn perip 10; # 限制同一个客户端ip
            limit_conn perserver 100;
        }

只有当 `request header` 被后端处理后，这个连接才进行计数

### 二、服务端限流

#### 1. Semaphore

JUC 包中提供的信号量工具，它的内部维护了一个同步队列，我们可以在每个请求进来的时候，尝试获取信号量，获取不到可以阻塞或者快速失败

简单样例：

```
Semaphore sp = new Semaphore(3);
sp.require(); // 阻塞获取
System.out.println("执行业务逻辑");
sp.release();
```

#### 2. RateLimiter

Guava 中基于令牌桶实现的一个限流工具，使用非常简单，通过方法 create() 创建一个桶，然后通过 acquire() 或者 tryAcquire() 获取令牌：

```
RateLimiter rateLimiter = RateLimiter.create(5); // 初始化令牌桶，每秒往桶里存放5个令牌
rateLimiter.acquire();                           // 自旋阻塞获取令牌，返回阻塞的时间，单位为秒
rateLimiter.tryAcquire();                        //
```

获取令牌，返回布尔结果，超过超时时间（默认为0，单位为毫秒）则返回失败

RateLimiter 在实现时，允许暴增请求的突发情况存在。

举个例子，我们有一个速率为每秒5个令牌的 RateLimiter：

当令牌桶空了的时候，如果继续获取一个令牌，那么会在下一次补充令牌的时候返回结果

但如果直接获取5个令牌，并不是等待桶内补齐5个令牌后再返回，而是仍旧会在令牌桶补充下一个令牌的时候直接返回，而预支令牌所需的补充时间会在下一次请求时进行补偿

```
public void testSmoothBursty() {
    RateLimiter r = RateLimiter.create(5);
    for (int i = 0; i++ < 2; ) {
        System.out.println("get 5 tokens: " + r.acquire(5) + "s");
        System.out.println("get 1 tokens: " + r.acquire(1) + "s");
        System.out.println("get 1 tokens: " + r.acquire(1) + "s");
        System.out.println("get 1 tokens: " + r.acquire(1) + "s");
        System.out.println("end");
    }
}
```

```
/**
* 控制台输出
* get 5 tokens: 0.0s      初始化时桶是空的，直接从空桶获取5个令牌
* get 1 tokens: 0.998068s 滞后效应，需要替前一个请求进行等待
* get 1 tokens: 0.196288s
* get 1 tokens: 0.200391s
* end
* get 5 tokens: 0.195756s
* get 1 tokens: 0.995625s 滞后效应，需要替前一个请求进行等待
* get 1 tokens: 0.194603s
* get 1 tokens: 0.196866s
* end
*/
```

#### 3. Hystrix

Netflix 开源的熔断组件，支持两种资源隔离策略：THREAD（默认）或者 SEMAPHORE

    线程池：每个 command 运行在一个线程中，限流是通过线程池的大小来控制的

    信号量：command 是运行在调用线程中，但是通过信号量的容量来进行限流

线程池策略对每一个资源创建一个线程池以进行流量管控，优点是资源隔离彻底，缺点是容易造成资源碎片化。

使用样例：

```
// HelloWorldHystrixCommand要使用Hystrix功能
public class HelloWorldHystrixCommand extends HystrixCommand {
    private final String name;
    public HelloWorldHystrixCommand(String name) {
        super(HystrixCommandGroupKey.Factory.asKey("ExampleGroup"));
        this.name = name;
    }
    // 如果继承的是HystrixObservableCommand，要重写Observable construct()
    @Override
    protected String run() {
        return "Hello " + name;
    }
}
```

调用该 command：

```
String result = new HelloWorldHystrixCommand("HLX").execute();
System.out.println(result);  // 打印出Hello HLX
```

Hystrix 已经在 2018 年停止开发，官方推荐替代项目 Resilience4j

更多使用介绍可查看：Hystrix 熔断器的使用

#### 4. Sentinel

阿里开源的限流熔断组件，底层统计采用滑动窗口算法，限流方面有两种使用方式：API 调用和注解，内部采插槽链来统计和执行校验规则。

通过为方法增加注解 @SentinelResource(String name)或者手动调用 SphU.entry(String name)方法开启流控。

使用API手动调用流控示例：

```
@Test
public void testRule() {
    // 配置规则.
    initFlowRules();
    int count = 0;
    while (true) {
        try (Entry entry = SphU.entry("HelloWorld")) {
            // 被保护的逻辑
            System.out.println("run " + ++count + " times");
        } catch (BlockException ex) {
            // 处理被流控的逻辑
            System.out.println("blocked after " + count);
            break;
        }
    }
}

// 输出结果：
// run 1 times
// run 2 times
// run 3 times
```

关于 Sentinel 的详细介绍可查看：Sentinel- 分布式系统的流量哨兵

### 三、分布式下限流方案

线上环境下，如果对共用资源（如数据库、下游服务）做统一流量限制，那么单机限流显然不能满足，而需要分布式流控方案。

分布式限流主要采取中心系统流量管控的方案，由一个中心系统统一管控流量配额。

这种方案的缺点就是中心系统的可靠性，所以一般需要备用方案，在中心系统不可用时，退化为单机流控。

#### 1. Tair 通过 incr 方法实现简单窗口

实现方式是使用 incr() 自增方法来计数并与阈值进行大小比较。

```
public boolean tryAcquire(String key) {
    // 以秒为单位构建tair的key
    String wrappedKey = wrapKey(key);
    // 每次请求+1，初始值为0，key的有效期设置5s
    Result<Integer> result = tairManager.incr(NAMESPACE, wrappedKey, 1, 0, 5);
    return result.isSuccess() && result.getValue() <= threshold;
}

private String wrapKey(String key) {
    long sec = System.currentTimeMillis() / 1000L;
    return key + ":" + sec;
}
```

【备注】incr 方法的参数说明

```
// 方法定义：
Result incr(int namespace, Serializable key, int value, int defaultValue, int expireTime)


/* 参数含义：
namespace - 申请时分配的 namespace
key - key 列表，不超过 1k
value - 增加量
defaultValue - 第一次调用 incr 时的 key 的 count 初始值，第一次返回的值为 defaultValue + value。
expireTime - 数据过期时间，单位为秒，可设相对时间或绝对时间（Unix 时间戳）。
*/
```

#### 2. Redis 通过 lua 脚本实现固定窗口限流

看到两种方法，先记下，后面对比

一.

与 Tair 实现方式类似，不过 redis 的 incr() 方法不能原子性的设置过期时间，所以需要使用 lua 脚本，在第一次调用返回1时，设置下过期时间为1秒。

```
local current
current = redis.call("incr",KEYS[1])
if tonumber(current) == 1 then
    redis.call("expire",KEYS[1],1)
end
return current
```

二.

Redis 中的固定窗口限流是使用 incr 命令实现的，incr 命令通常用来自增计数；如果我们使用时间戳信息作为 key，自然就可以统计每秒的请求量了，以此达到限流目的。

这里有两点要注意。

    对于不存在的 key，第一次新增时，value 始终为 1。
    INCR 和 EXPIRE 命令操作应该在一个原子操作中提交，以保证每个 key 都正确设置了过期时间，不然会有 key 值无法自动删除而导致的内存溢出。

由于 Redis 中实现事务的复杂性，所以这里直接只用 lua 脚本来实现原子操作。下面是 lua 脚本内容。

```
local count = redis.call("incr",KEYS[1])
if count == 1 then
  redis.call('expire',KEYS[1],ARGV[2])
end
if count > tonumber(ARGV[1]) then
  return 0
end
return 1
```

3. Redis 通过 lua 脚本实现令牌桶

实现思路是获取令牌后，用SET记录 “请求时间” 和 “剩余 token 数量”。

每次请求令牌时，通过这两个参数和请求的时间、流速等参数进行计算，返回是否获取令牌成功。

获取令牌lua脚本：

```lua
local ratelimit_info = redis.pcall('HMGET',KEYS[1],'last_time','current_token')
local last_time = ratelimit_info[1]
local current_token = tonumber(ratelimit_info[2])
local max_token = tonumber(ARGV[1])
local token_rate = tonumber(ARGV[2])
local current_time = tonumber(ARGV[3])
local reverse_time = 1000/token_rate

if current_token == nil then
  current_token = max_token
  last_time = current_time
else
  local past_time = current_time-last_time
  local reverse_token = math.floor(past_time/reverse_time)
  current_token = current_token+reverse_token
  last_time = reverse_time*reverse_token+last_time
  if current_token>max_token then
    current_token = max_token
  end
end

local result = 0
if(current_token>0) then
  result = 1
  current_token = current_token-1
end

redis.call('HMSET',KEYS[1],'last_time',last_time,'current_token',current_token)
redis.call('pexpire',KEYS[1],math.ceil(reverse_time*(max_token-current_token)+(current_time-last_time)))
return result
```

初始化令牌桶lua脚本：

```lua
local result=1
redis.pcall("HMSET",KEYS[1],"last_mill_second",ARGV[1],"curr_permits",ARGV[2],"max_burst",ARGV[3],"rate",ARGV[4])
return result
```

#### 4. 滑动窗口限流

滑动窗口限流可以大幅度降低因为窗口临界突变带来的问题，使用 Redis 来实现滑动窗口限流主要使用 ZSET 有序集合来实现滑动窗口限流

ZSET 集合有下面几个特点：

    ZSET 集合中的  key 值可以自动排序。
    ZSET 集合中的 value 不能有重复值。
    ZSET 集合可以方便的使用 ZCARD 命令获取元素个数。
    ZSET 集合可以方便的使用 ZREMRANGEBYLEX 命令移除指定范围的 key 值。

基于上面的四点特性，可以编写出基于 ZSET 的滑动窗口限流 lua 脚本。

    --KEYS[1]: 限流 key
    --ARGV[1]: 时间戳 - 时间窗口
    --ARGV[2]: 当前时间戳（作为score）
    --ARGV[3]: 阈值
    --ARGV[4]: score 对应的唯一value
    -- 1. 移除时间窗口之前的数据
    redis.call('zremrangeByScore', KEYS[1], 0, ARGV[1])
    -- 2. 统计当前元素数量
    local res = redis.call('zcard', KEYS[1])
    -- 3. 是否超过阈值

```lua
    if (res == nil) or (res < tonumber(ARGV[3])) then
        redis.call('zadd', KEYS[1], ARGV[2], ARGV[4])
        return 1
    else
        return 0
    end
```
